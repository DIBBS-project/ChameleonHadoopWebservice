* ChameleonClusters

This project enables the deployment of clusters on the Chameleon infrastructure.
It is leveraging the *OpenStack API*,  the web framework *django* and the module
*django Rest framework* to build a REST API.

** Installation

The  project  contains  a  *requirements.txt* files  that  contains  all  python
dependencies required to  run the tool. To install all  the dependencies run the
following command:

#+BEGIN_src shell
pip install -r requirements.txt
#+END_src

** Running

Launch the webservice with the following commands:

#+BEGIN_src shell
sudo pip install -r requirements.txt
bash reset_app.sh

sudo python manage.py runserver 0.0.0.0:8000
#+END_src


** Call the webservice

Here is an example program that run an Hadoop job using the Webservice:

#+BEGIN_src shell
#!/usr/bin/env bash

REMOTE_HADOOP_WEBSERVICE_HOST="http://129.114.111.66:8000"

function extract_id {

    RESULT=$(echo $1 | sed 's/.*"id"://g' | sed 's/,.*//g')

    echo "$RESULT"
}

# Clean HDFS folder used by this example
curl -H "Content-Type: application/json" -X GET $REMOTE_HADOOP_WEBSERVICE_HOST/hdfs/rmdir/user/root/

# Upload local files to the application
curl -i -X POST -F 'data=@test.jar' $REMOTE_HADOOP_WEBSERVICE_HOST/fs/upload/test.jar/

# Copy test.txt to HDFS in the "input" file
curl -i -X GET $REMOTE_HADOOP_WEBSERVICE_HOST/hdfs/mkdir/user/root/
curl -i -X POST -F 'data=@test.txt' $REMOTE_HADOOP_WEBSERVICE_HOST/hdfs/upload/user/root/input/

# Create Hadoop job
HADOOP_JOB_CREATION_OUTPUT=$(curl -H "Content-Type: application/json" -X POST -d "{\"name\": \"test\", \"command\": \"test.jar input output dummyparameter\"}" $REMOTE_HADOOP_WEBSERVICE_HOST/jobs/)
HADOOP_JOB_ID=$(extract_id $HADOOP_JOB_CREATION_OUTPUT)

# Run "test.jar" with hadoop
curl -i -X GET  $REMOTE_HADOOP_WEBSERVICE_HOST/run_hadoop_job/$HADOOP_JOB_ID/

sleep 30

# Collect result files: "output" located in HDFS will be copied to the "output.txt" file
curl -H "Content-Type: application/json" -X GET $REMOTE_HADOOP_WEBSERVICE_HOST/hdfs/download/user/root/output/part-r-00000/

exit 0

#+END_src


*** Local file system

| URL         | HTTP Method | Action            | Supported | Comment |
|-------------+-------------+-------------------+-----------+---------|
| /fs/ls/[path]/     | GET         | list files located in the path    | Yes       |         |
| /users/     | POST        | add a new user    | Yes       |         |
| /users/[id] | GET         | details of a user | Yes       |         |
| /users/[id] | PUT         | update a user     | Yes       |         |
| /users/[id] | DELETE      | delete a user     | Yes       |         |

*** HDFS file system

| URL         | HTTP Method | Action            | Supported | Comment |
|-------------+-------------+-------------------+-----------+---------|
| /sites/     | GET         | list all   sites  | Yes       |         |
| /sites/     | POST        | add a new site    | Yes       |         |
| /sites/[id] | GET         | details of a site | Yes       |         |
| /sites/[id] | PUT         | update a site     | Yes       |         |
| /sites/[id] | DELETE      | delete a site     | Yes       |         |

*** Hadoop Jobs
